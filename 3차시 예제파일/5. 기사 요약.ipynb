{"cells":[{"cell_type":"markdown","metadata":{"id":"8eOL0ObMirGp"},"source":["## 5. 기사 요약\n","\n","[빈칸 및 해설](https://blog.naver.com/nsun527/222803261033)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ds_OHYfsioYh"},"outputs":[],"source":["!pip install pyLDAvis\n","\n","from nltk.corpus import 😊\n","from sklearn.datasets import 😊\n","from gensim import 😊\n","from gensim.summarization.summarizer import summarize\n","\n","😊\n","😊\n","import gensim"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"waL_HoGGioYn"},"outputs":[],"source":["# 기사 번호\n","ARTICLE_NO = 1\n","\n","# 불용어 다운로드\n","😊\n","\n","documents = fetch_20newsgroups(shuffle=True, remove=('headers', 'footers', 'quotes')).data\n","print(f'Got {😊(documents)} samples.')\n","print(😊[ARTICLE_NO])\n","\n","news_df = pd.😊({'document': documents})\n","\n","# 알파벳이 아닌 모든 문자를 제거합니다.\n","news_df['clean_doc'] = news_df['document'].str.😊(😊, ' ')\n","# 길이가 3 초과인 단어만 가져옵니다.\n","news_df['clean_doc'] = news_df['clean_doc'].apply(lambda x: ' '.join([w for w in x.split() if len(w)>3]))\n","# 소문자로 변환합니다.\n","news_df['clean_doc'] = news_df['clean_doc'].apply(lambda x: x.lower())\n","news_df['clean_doc'][ARTICLE_NO]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BFQ9EBT3ioYo"},"outputs":[],"source":["# 불용어를 받아오고 토큰화시킨 뒤, 불용어를 제거합니다.\n","stop_words = 😊\n","tokenized_doc = news_df['clean_doc'].apply(lambda x: x.😊()) \n","tokenized_doc = tokenized_doc.apply(lambda x: [item for item in x😊])\n","print(😊[ARTICLE_NO])\n","\n","# 뉴스에서의 단어 인베딩과 빈도수를 기록합니다.\n","dictionary = corpora.😊(tokenized_doc)\n","corpus = [dictionary.doc2bow(text) for text in tokenized_doc]\n","print(corpus[ARTICLE_NO]) "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1SwpYiKlioYp"},"outputs":[],"source":["# 20개의 토픽, k=20\n","NUM_TOPICS = 20\n","# corpus를 가지고 lda모델 학습 num_topics은 토픽의 개수 , passes는 알고리즘의 동작 횟수\n","ldamodel = gensim.models.ldamodel.😊(corpus, num_topics = NUM_TOPICS, id2word=dictionary, passes=15)\n","# 학습한 lda모델의 토픽별 핵심 단어 확인, num_words 는 단어의 개수\n","topics = ldamodel.😊(num_words=4)\n","# 결과 출력\n","for topic in topics:\n","    print(topic)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AUVGdzXNioYq"},"outputs":[],"source":["article = '''\n","\n","'''\n","\n","print(summarize(article, word_count = 15))"]}],"metadata":{"colab":{"collapsed_sections":[],"name":"5. 기사 요약.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3.9.7 ('base')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"20efb7bbc3e880fa5daaecac3f0f42ac0fcde1e987afd03e25384b1713bb4579"}}},"nbformat":4,"nbformat_minor":0}
